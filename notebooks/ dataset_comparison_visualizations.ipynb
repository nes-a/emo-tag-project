{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nes-a/emo-tag-project/blob/main/notebooks/%20dataset_comparison_visualizations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mZRJqYnx4m11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "metadata": {
        "id": "jLXxm9rS6zxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOEMOTIONS_LABELS = [\n",
        "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion',\n",
        "    'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
        "    'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism',\n",
        "    'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
        "]"
      ],
      "metadata": {
        "id": "rfDnjHTi67jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define load_and_process_go_emotions_split function"
      ],
      "metadata": {
        "id": "fz9jVbUF7AFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_go_emotions_split(filepath):\n",
        "    try:\n",
        "        # Load without header, assign names explicitly based on the structure observed\n",
        "        df_split = pd.read_csv(filepath, sep='\\t', encoding='utf-8', header=None, names=['text', 'emotion_ids_str', 'comment_id'])\n",
        "        print(f\"Loaded {filepath.split('/')[-1]}. Initial shape: {df_split.shape}\")\n",
        "        print(f\"Columns in {filepath.split('/')[-1]} after initial load: {df_split.columns.tolist()}\")\n",
        "\n",
        "        # Convert comma-separated string of numerical IDs into a list of integers\n",
        "        df_split['emotion_ids_list'] = df_split['emotion_ids_str'].apply(\n",
        "            lambda x: [int(label_id) for label_id in str(x).split(',') if label_id.strip().isdigit()]\n",
        "        )\n",
        "\n",
        "        # Map these numerical IDs to the actual emotion names using GOEMOTIONS_LABELS\n",
        "        df_split['emotion_names'] = df_split['emotion_ids_list'].apply(\n",
        "            lambda ids: [GOEMOTIONS_LABELS[idx] for idx in ids if idx < len(GOEMOTIONS_LABELS)]\n",
        "        )\n",
        "\n",
        "        # Select only the 'text' and the new 'emotion_names' list column\n",
        "        df_processed = df_split[['text', 'emotion_names']].rename(columns={'emotion_names': 'emotion'}).copy()\n",
        "        print(f\"Processed {filepath.split('/')[-1]}. Final shape: {df_processed.shape}\")\n",
        "        return df_processed\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: {filepath.split('/')[-1]} not found. Please ensure all 3 GoEmotions TSV files are in the specified Drive path.\")\n",
        "        return pd.DataFrame(columns=['text', 'emotion'])\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred loading or processing {filepath.split('/')[-1]}: {e}\")\n",
        "        return pd.DataFrame(columns=['text', 'emotion'])"
      ],
      "metadata": {
        "id": "-kSUQxGQ7BKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define paths"
      ],
      "metadata": {
        "id": "VxFn6CYg7Dnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "go_emotions_data_path = \"/content/drive/MyDrive/ML_Emotion_Classifier/data/go_emotions/\"\n",
        "go_emotions_train_filepath = f\"{go_emotions_data_path}train.tsv\"\n",
        "go_emotions_dev_filepath = f\"{go_emotions_data_path}dev.tsv\"\n",
        "go_emotions_test_filepath = f\"{go_emotions_data_path}test.tsv\"\n",
        "\n",
        "synthetic_data_filepath = \"/content/drive/MyDrive/ML_Emotion_Classifier/data/synthetic/df_synthetic_goemotions_processed.csv\" # Corrected filename"
      ],
      "metadata": {
        "id": "hGv2ssvq7GRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and process GoEmotions splits"
      ],
      "metadata": {
        "id": "bFzrvDAG7Iag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Loading and processing official GoEmotions splits ---\")\n",
        "df_go_emotions_train = load_and_process_go_emotions_split(go_emotions_train_filepath)\n",
        "df_go_emotions_val = load_and_process_go_emotions_split(go_emotions_dev_filepath)\n",
        "df_go_emotions_test = load_and_process_go_emotions_split(go_emotions_test_filepath)\n",
        "print(\"--------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "yp9jdMTs7KsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load synthetic data"
      ],
      "metadata": {
        "id": "E7nVYNZx7NP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Loading synthetic data ---\")\n",
        "df_synthetic = pd.read_csv(synthetic_data_filepath)\n",
        "\n",
        "def parse_emotion_string(s):\n",
        "    if pd.isna(s):\n",
        "        return []\n",
        "    s = str(s).strip()\n",
        "    if s.startswith('[') and s.endswith(']'):\n",
        "        s = s[1:-1]\n",
        "\n",
        "    emotions = [e.strip().strip(\"'\\\"\") for e in s.split(',') if e.strip()]\n",
        "    return emotions\n",
        "\n",
        "df_synthetic['emotion'] = df_synthetic['emotion'].apply(parse_emotion_string)\n",
        "print(f\"Loaded synthetic data. Shape: {df_synthetic.shape}\")\n",
        "print(\"--------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "uqiIRyXE7PdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine training data: df_go_emotions_train + df_synthetic"
      ],
      "metadata": {
        "id": "PswXAfAC7svc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Combining datasets ---\")\n",
        "train_df = pd.concat([df_go_emotions_train, df_synthetic], ignore_index=True)\n",
        "val_df = df_go_emotions_val # Validation set remains official dev data\n",
        "test_df = df_go_emotions_test # Test set remains official test data\n",
        "print(f\"Combined train_df shape: {train_df.shape}\")\n",
        "print(f\"Val_df shape: {val_df.shape}\")\n",
        "print(f\"Test_df shape: {test_df.shape}\")\n",
        "print(\"--------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "TgzpNH649Ayc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-hot encoding"
      ],
      "metadata": {
        "id": "gE9Zomvi9FoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Applying Multi-hot Encoding ---\")\n",
        "mlb = MultiLabelBinarizer()\n",
        "\n",
        "# Fit on all possible labels from combined training data\n",
        "mlb.fit([GOEMOTIONS_LABELS])\n",
        "\n",
        "# Transform emotion lists into multi-hot encoded labels\n",
        "train_df['multi_hot_labels'] = list(mlb.transform(train_df['emotion']))\n",
        "val_df['multi_hot_labels'] = list(mlb.transform(val_df['emotion']))\n",
        "test_df['multi_hot_labels'] = list(mlb.transform(test_df['emotion']))\n",
        "\n",
        "# Convert multi_hot_labels to tensors and rename to 'labels' for Hugging Face Trainer\n",
        "train_df['labels'] = train_df['multi_hot_labels'].apply(lambda x: pd.Series(x).astype(float).values)\n",
        "val_df['labels'] = val_df['multi_hot_labels'].apply(lambda x: pd.Series(x).astype(float).values)\n",
        "test_df['labels'] = test_df['multi_hot_labels'].apply(lambda x: pd.Series(x).astype(float).values)\n",
        "\n",
        "print(\"Multi-hot encoding applied.\")\n",
        "print(f\"Example train_df 'labels' entry: {train_df['labels'][0]}\")\n",
        "print(f\"Number of emotion classes: {len(mlb.classes_)}\")\n",
        "print(f\"Classes: {mlb.classes_.tolist()}\")\n",
        "print(\"--------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "MVUmN1BX9Gdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert to Hugging Face Dataset"
      ],
      "metadata": {
        "id": "mRWq3dtf9aQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Converting to Hugging Face Dataset ---\")\n",
        "\n",
        "train_hf_dataset = Dataset.from_pandas(train_df)\n",
        "val_hf_dataset = Dataset.from_pandas(val_df)\n",
        "test_hf_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "print(\"Hugging Face Datasets created.\")\n",
        "print(f\"train_hf_dataset columns: {train_hf_dataset.column_names}\")\n",
        "print(f\"val_hf_dataset columns: {val_hf_dataset.column_names}\")\n",
        "print(f\"test_hf_dataset columns: {test_hf_dataset.column_names}\")\n",
        "print(\"--------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "m40l8lMv9a2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ],
      "metadata": {
        "id": "0t3AGk139gnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Applying Tokenization ---\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "tokenized_train_dataset = train_hf_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_val_dataset = val_hf_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test_dataset = test_hf_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"--- Removing columns and setting format ---\")\n",
        "# Removed \"__index__\"\n",
        "tokenized_train_dataset = tokenized_train_dataset.remove_columns([\"text\", \"emotion\", \"multi_hot_labels\"])\n",
        "tokenized_train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "tokenized_val_dataset = tokenized_val_dataset.remove_columns([\"text\", \"emotion\", \"multi_hot_labels\"])\n",
        "tokenized_val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"text\", \"emotion\", \"multi_hot_labels\"])\n",
        "tokenized_test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "print(\"Datasets prepared with multi-hot labels for train, validation, and test.\")\n",
        "print(\"--------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "cDjISzEq9hQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Dataset Sizes"
      ],
      "metadata": {
        "id": "xvpvKU8-9i_P"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "027d34b6"
      },
      "source": [
        "visualization_output_dir = \"/content/drive/MyDrive/ML_Emotion_Classifier/visualizations/\" #change to own path\n",
        "\n",
        "os.makedirs(visualization_output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Visualization output directory set to: {visualization_output_dir}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Generating Dataset Size Visualization ---\")\n",
        "dataset_sizes = {\n",
        "    \"GoEmotions Train (Original)\": len(df_go_emotions_train),\n",
        "    \"GoEmotions Validation\": len(df_go_emotions_val),\n",
        "    \"GoEmotions Test\": len(df_go_emotions_test),\n",
        "    \"Synthetic Data\": len(df_synthetic),\n",
        "    \"Combined Train Data\": len(train_df)\n",
        "}\n",
        "\n",
        "df_sizes = pd.DataFrame(list(dataset_sizes.items()), columns=['Dataset', 'Number of Samples'])\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x='Dataset', y='Number of Samples', data=df_sizes, palette='viridis')\n",
        "plt.title('Number of Samples in Each Dataset', fontsize=16)\n",
        "plt.xlabel('Dataset', fontsize=12)\n",
        "plt.ylabel('Number of Samples', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(visualization_output_dir, 'dataset_sizes.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"--------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "fZpJuHal_Xj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Emotion Distribution"
      ],
      "metadata": {
        "id": "WiVgiJ5h_dKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Generating Emotion Distribution Visualizations ---\")\n",
        "\n",
        "def get_emotion_counts(df, top_n=15):\n",
        "    all_emotions = [emotion for sublist in df['emotion'] for emotion in sublist]\n",
        "    emotion_series = pd.Series(all_emotions)\n",
        "    return emotion_series.value_counts().head(top_n)\n",
        "\n",
        "# Get counts for each dataset\n",
        "go_emotions_train_counts = get_emotion_counts(df_go_emotions_train)\n",
        "synthetic_counts = get_emotion_counts(df_synthetic)\n",
        "combined_train_counts = get_emotion_counts(train_df)\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(14, 18))\n",
        "fig.suptitle('Top Emotion Distribution Across Datasets', fontsize=20)\n",
        "\n",
        "# Plot for GoEmotions Train\n",
        "sns.barplot(x=go_emotions_train_counts.index, y=go_emotions_train_counts.values, ax=axes[0], palette='coolwarm')\n",
        "axes[0].set_title('GoEmotions Train (Original) - Top Emotions', fontsize=14)\n",
        "axes[0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Plot for Synthetic Data\n",
        "sns.barplot(x=synthetic_counts.index, y=synthetic_counts.values, ax=axes[1], palette='coolwarm')\n",
        "axes[1].set_title('Synthetic Data - Top Emotions', fontsize=14)\n",
        "axes[1].set_ylabel('Frequency', fontsize=12)\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Plot for Combined Train Data\n",
        "sns.barplot(x=combined_train_counts.index, y=combined_train_counts.values, ax=axes[2], palette='coolwarm')\n",
        "axes[2].set_title('Combined Train Data - Top Emotions', fontsize=14)\n",
        "axes[2].set_ylabel('Frequency', fontsize=12)\n",
        "axes[2].tick_params(axis='x', rotation=45)\n",
        "axes[2].grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
        "plt.savefig(os.path.join(visualization_output_dir, 'top_emotion_distribution.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"--------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "de-wUWV1_ifN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Text Length Distribution"
      ],
      "metadata": {
        "id": "geZg2-i4_m9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Generating Text Length Distribution Visualizations ---\")\n",
        "\n",
        "# Calculate text lengths\n",
        "df_go_emotions_train['text_length'] = df_go_emotions_train['text'].apply(len)\n",
        "df_synthetic['text_length'] = df_synthetic['text'].apply(len)\n",
        "train_df['text_length'] = train_df['text'].apply(len) # Ensure this is calculated on the combined df too\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(14, 18))\n",
        "fig.suptitle('Text Length Distribution Across Datasets', fontsize=20)\n",
        "\n",
        "# Plot for GoEmotions Train\n",
        "sns.histplot(df_go_emotions_train['text_length'], bins=50, kde=True, ax=axes[0], color='skyblue')\n",
        "axes[0].set_title('GoEmotions Train (Original) - Text Length', fontsize=14)\n",
        "axes[0].set_xlabel('Text Length (Characters)', fontsize=12)\n",
        "axes[0].set_ylabel('Count', fontsize=12)\n",
        "axes[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Plot for Synthetic Data\n",
        "sns.histplot(df_synthetic['text_length'], bins=50, kde=True, ax=axes[1], color='salmon')\n",
        "axes[1].set_title('Synthetic Data - Text Length', fontsize=14)\n",
        "axes[1].set_xlabel('Text Length (Characters)', fontsize=12)\n",
        "axes[1].set_ylabel('Count', fontsize=12)\n",
        "axes[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Plot for Combined Train Data\n",
        "sns.histplot(train_df['text_length'], bins=50, kde=True, ax=axes[2], color='lightgreen')\n",
        "axes[2].set_title('Combined Train Data - Text Length', fontsize=14)\n",
        "axes[2].set_xlabel('Text Length (Characters)', fontsize=12)\n",
        "axes[2].set_ylabel('Count', fontsize=12)\n",
        "axes[2].grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
        "plt.savefig(os.path.join(visualization_output_dir, 'text_length_distribution.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"--------------------------------------------------------------------------------\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "ru8yh_E54ekH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzing Increase in Underrepresented Emotions"
      ],
      "metadata": {
        "id": "hQsw8xAgAeaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Analyzing Increase in Underrepresented Emotions ---\")\n",
        "\n",
        "def get_all_emotion_occurrences(df):\n",
        "    all_emotions = []\n",
        "    for emotions_list in df['emotion']:\n",
        "        all_emotions.extend(emotions_list)\n",
        "    return pd.Series(all_emotions)\n",
        "\n",
        "# Emotion counts for the original GoEmotions training data\n",
        "original_emotion_counts = get_all_emotion_occurrences(df_go_emotions_train).value_counts()\n",
        "\n",
        "N_LEAST_REPRESENTED = 10\n",
        "least_represented_emotions = original_emotion_counts.sort_values(ascending=True).head(N_LEAST_REPRESENTED).index.tolist()\n",
        "\n",
        "print(f\"\\nTop {N_LEAST_REPRESENTED} least represented emotions in original GoEmotions training data:\")\n",
        "print(original_emotion_counts.loc[least_represented_emotions].sort_values(ascending=True))"
      ],
      "metadata": {
        "id": "mCMQULlIAnAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emotion counts for the combined training data"
      ],
      "metadata": {
        "id": "taUwhDPhAoqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_emotion_counts = get_all_emotion_occurrences(train_df).value_counts()\n",
        "\n",
        "comparison_data = []\n",
        "for emotion in least_represented_emotions:\n",
        "    original_count = original_emotion_counts.get(emotion, 0)\n",
        "    combined_count = combined_emotion_counts.get(emotion, 0)\n",
        "    increase = combined_count - original_count\n",
        "    percentage_increase = (increase / original_count * 100) if original_count > 0 else (100 if combined_count > 0 else 0)\n",
        "    comparison_data.append({\n",
        "        'Emotion': emotion,\n",
        "        'Original Count': original_count,\n",
        "        'Combined Count': combined_count,\n",
        "        'Increase': increase,\n",
        "        'Percentage Increase (%)': f\"{percentage_increase:.2f}%\"\n",
        "    })\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "df_comparison = df_comparison.sort_values(by='Original Count', ascending=True)\n",
        "\n",
        "print(\"\\nComparison of Underrepresented Emotions (Original vs. Combined Data):\")\n",
        "print(df_comparison.to_string(index=False))"
      ],
      "metadata": {
        "id": "xdaOZ7YnAuPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the increase"
      ],
      "metadata": {
        "id": "6KzU3LjBAv5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_plot = df_comparison[['Emotion', 'Original Count', 'Combined Count']].melt(\n",
        "    id_vars='Emotion', var_name='Dataset Type', value_name='Count'\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(\n",
        "    x='Emotion',\n",
        "    y='Count',\n",
        "    hue='Dataset Type',\n",
        "    data=df_plot,\n",
        "    palette='pastel',\n",
        "    order=df_comparison['Emotion']\n",
        ")\n",
        "plt.title(f'Increase in {N_LEAST_REPRESENTED} Least Represented Emotions (Original vs. Combined)', fontsize=16)\n",
        "plt.xlabel('Emotion', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend(title='Dataset')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(visualization_output_dir, 'least_represented_emotions_increase.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "ZXKakzDrAZyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyzing All Emotion Frequencies (Original vs. Combined Data)"
      ],
      "metadata": {
        "id": "hopIoKExBHr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Analyzing All Emotion Frequencies (Original vs. Combined Data) ---\")\n",
        "\n",
        "def get_all_emotion_occurrences(df):\n",
        "    all_emotions = []\n",
        "    for emotions_list in df['emotion']:\n",
        "        all_emotions.extend(emotions_list)\n",
        "    return pd.Series(all_emotions)\n",
        "\n",
        "# Get emotion counts for the original GoEmotions training data\n",
        "original_emotion_counts = get_all_emotion_occurrences(df_go_emotions_train).value_counts()\n",
        "\n",
        "# Get emotion counts for the combined training data\n",
        "combined_emotion_counts = get_all_emotion_occurrences(train_df).value_counts()\n",
        "\n",
        "# Create a DataFrame to compare counts for ALL emotions\n",
        "comparison_data_all_emotions = []\n",
        "for emotion in GOEMOTIONS_LABELS:\n",
        "    original_count = original_emotion_counts.get(emotion, 0)\n",
        "    combined_count = combined_emotion_counts.get(emotion, 0)\n",
        "    increase = combined_count - original_count\n",
        "    percentage_increase = (increase / original_count * 100) if original_count > 0 else (100 if combined_count > 0 else 0)\n",
        "    comparison_data_all_emotions.append({\n",
        "        'Emotion': emotion,\n",
        "        'Original Count': original_count,\n",
        "        'Combined Count': combined_count,\n",
        "        'Increase': increase,\n",
        "        'Percentage Increase (%)': f\"{percentage_increase:.2f}%\"\n",
        "    })\n",
        "\n",
        "df_comparison_all_emotions = pd.DataFrame(comparison_data_all_emotions)\n",
        "df_comparison_all_emotions = df_comparison_all_emotions.sort_values(by='Original Count', ascending=True)\n",
        "\n",
        "print(\"\\nComparison of All Emotion Frequencies (Original vs. Combined Data):\")\n",
        "print(df_comparison_all_emotions.to_string(index=False))"
      ],
      "metadata": {
        "id": "cncWfpKzBbxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the comparison for all emotions"
      ],
      "metadata": {
        "id": "BnDyYsohBfDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_plot_all_emotions = df_comparison_all_emotions[['Emotion', 'Original Count', 'Combined Count']].melt(\n",
        "    id_vars='Emotion', var_name='Dataset Type', value_name='Count'\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "sns.barplot(\n",
        "    x='Emotion',\n",
        "    y='Count',\n",
        "    hue='Dataset Type',\n",
        "    data=df_plot_all_emotions,\n",
        "    palette='viridis',\n",
        "    order=df_comparison_all_emotions['Emotion']\n",
        ")\n",
        "plt.title('All Emotion Frequencies: Original GoEmotions Train vs. Combined Train Data', fontsize=18)\n",
        "plt.xlabel('Emotion', fontsize=14)\n",
        "plt.ylabel('Frequency', fontsize=14)\n",
        "plt.xticks(rotation=60, ha='right', fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend(title='Dataset', fontsize=10, title_fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(visualization_output_dir, 'all_emotion_frequencies.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "rsQIC1t6BBmf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}